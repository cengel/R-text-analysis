<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 1 Analysing Texts | Text Analysis with R</title>
  <meta name="description" content="Workshop materials for Text Analysis in R">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 1 Analysing Texts | Text Analysis with R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Workshop materials for Text Analysis in R" />
  <meta name="github-repo" content="cengel/R-text-analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Analysing Texts | Text Analysis with R" />
  
  <meta name="twitter:description" content="Workshop materials for Text Analysis in R" />
  

<meta name="author" content="Claudia Engel, Scott Bailey">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="textprep.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Text Analysis with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prerequisites</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#references"><i class="fa fa-check"></i>References</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="textanalysis.html"><a href="textanalysis.html"><i class="fa fa-check"></i><b>1</b> Analysing Texts</a><ul>
<li class="chapter" data-level="1.1" data-path="textanalysis.html"><a href="textanalysis.html#reading-text-into-r"><i class="fa fa-check"></i><b>1.1</b> Reading text into R</a></li>
<li class="chapter" data-level="1.2" data-path="textanalysis.html"><a href="textanalysis.html#string-operations"><i class="fa fa-check"></i><b>1.2</b> String operations</a></li>
<li class="chapter" data-level="1.3" data-path="textanalysis.html"><a href="textanalysis.html#tokenize-lowercase"><i class="fa fa-check"></i><b>1.3</b> Tokenize, lowercase</a></li>
<li class="chapter" data-level="1.4" data-path="textanalysis.html"><a href="textanalysis.html#stopwords"><i class="fa fa-check"></i><b>1.4</b> Stopwords</a></li>
<li class="chapter" data-level="1.5" data-path="textanalysis.html"><a href="textanalysis.html#word-stemming"><i class="fa fa-check"></i><b>1.5</b> Word Stemming</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="textprep.html"><a href="textprep.html"><i class="fa fa-check"></i><b>2</b> Preparing Textual Data</a><ul>
<li class="chapter" data-level="2.1" data-path="textprep.html"><a href="textprep.html#frequencies"><i class="fa fa-check"></i><b>2.1</b> Frequencies</a></li>
<li class="chapter" data-level="2.2" data-path="textprep.html"><a href="textprep.html#term-frequency"><i class="fa fa-check"></i><b>2.2</b> Term frequency</a></li>
<li class="chapter" data-level="2.3" data-path="textprep.html"><a href="textprep.html#tf-idf"><i class="fa fa-check"></i><b>2.3</b> Tf-idf</a></li>
<li class="chapter" data-level="2.4" data-path="textprep.html"><a href="textprep.html#n-grams"><i class="fa fa-check"></i><b>2.4</b> N-Grams</a></li>
<li class="chapter" data-level="2.5" data-path="textprep.html"><a href="textprep.html#co-ocurrcence"><i class="fa fa-check"></i><b>2.5</b> Co-ocurrcence</a></li>
<li class="chapter" data-level="2.6" data-path="textprep.html"><a href="textprep.html#document-term-matrix"><i class="fa fa-check"></i><b>2.6</b> Document-Term Matrix</a></li>
<li class="chapter" data-level="2.7" data-path="textprep.html"><a href="textprep.html#sentiment-analysis"><i class="fa fa-check"></i><b>2.7</b> Sentiment analysis</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Text Analysis with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="textanalysis" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Analysing Texts</h1>
<blockquote>
<p>Learning Objectives</p>
<ul>
<li>to come</li>
</ul>
</blockquote>
<hr />
<p>We’ll use several libraries today. <code>sotu</code> will provide the metadata and text of State of the Union speeches ranging from George Washington to Barack Obama. <code>tidyverse</code> provides many of the standard “verbs” for working with our data. <code>tidytext</code> provides specific functions for a “tidy” approach to working with textual data. <code>readtext</code> provides a function well suited to reading textual data from a large number of formats into R.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sotu)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(tidytext)
<span class="kw">library</span>(readtext)</code></pre>
<div id="reading-text-into-r" class="section level2">
<h2><span class="header-section-number">1.1</span> Reading text into R</h2>
<p>First, let’s look at the data in the <code>sotu</code> package. The metadata and texts come separately. We’ll use the supplied metadata object, but we’re going to use a utility function (<code>sotu_dir</code>) in the package to write the texts to disk so that we can practice reading text files from disk.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Let&#39;s take a quick look at the state of the union metadata</span>
<span class="kw">summary</span>(sotu_meta)
<span class="co"># sotu_dir writes the text files to a temporary dir, but you could specific where you want them.</span>
fp &lt;-<span class="st"> </span><span class="kw">sotu_dir</span>()
<span class="kw">head</span>(fp)</code></pre>
<p>Now that we have the files on disk, and a list of filepaths stored in the <code>fp</code> variable, we can use <code>readtext</code> to read the texts into a new variable.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># let&#39;s then read in the files with readtext</span>
texts &lt;-<span class="st"> </span><span class="kw">readtext</span>(fp)
<span class="kw">head</span>(texts)</code></pre>
<p>So that we can work with a single tabular dataset with a tidy approach, we’ll convert the metadata and text tables to tibbles, and combine them into a single tibble. You can see that our texts are organized by alphabetical order, so first we’ll need to sort our metadata to match.</p>
<pre class="sourceCode r"><code class="sourceCode r">sotu_meta_tib &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(sotu_meta) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(president)

<span class="kw">head</span>(sotu_meta_tib)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We can now combine the sotu metadata with the texts</span>
<span class="co"># first, we&#39;ll turn both pieces of data into tibbles, then combine</span>
sotu_texts &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(texts)
sotu_whole &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(sotu_meta_tib, sotu_texts)
<span class="kw">glimpse</span>(sotu_whole)</code></pre>
<p>Now that we have our data, we need to think about cleaning it. Depending on the quality of your data, you might need to explicitly replace certain characters or words, remove urls or types of numbers, such as phone numbers, or otherwise clean up misspellings or errors. There are several ways to handle this sort of cleaning, but we’ll look at some straightforward string manipulation and replacement.</p>
</div>
<div id="string-operations" class="section level2">
<h2><span class="header-section-number">1.2</span> String operations</h2>
<p>R has many functions available to manipulate strings including functions like <code>grep</code> and <code>paste</code>, which come with the R base install.</p>
<p>Perhaps one of the most comprehensive packages is <code>stringi</code>. However, we will here take a look at the <code>stringr</code> package, which is part of the <code>tidyverse</code>, wraps a lot of the stringi functions, and is easier to begin with.</p>
<p>Below are a examples for a few functions that might be useful.</p>
<ul>
<li>How many words in each speech?</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str_count</span>(sotu_whole<span class="op">$</span>text, <span class="kw">boundary</span>(<span class="st">&quot;word&quot;</span>))</code></pre>
<ul>
<li>Measured by the average number of words per sentence for each speech - what is the length of the speech with the shortest/longest sentences?</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">range</span>(<span class="kw">str_count</span>(sotu_whole<span class="op">$</span>text, <span class="kw">boundary</span>(<span class="st">&quot;word&quot;</span>))<span class="op">/</span><span class="kw">str_count</span>(sotu_whole<span class="op">$</span>text, <span class="kw">boundary</span>(<span class="st">&quot;sentence&quot;</span>)))</code></pre>
<p>How man times does the word “citizen” appear in the speeches?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str_count</span>(sotu_whole<span class="op">$</span>text, <span class="st">&quot;[C|c]itizen&quot;</span>)</code></pre>
<p>What are the names of the documents in of the speeches where the word “citizen” does <strong>not</strong> occur?</p>
<pre class="sourceCode r"><code class="sourceCode r">sotu_whole<span class="op">$</span>doc_id[<span class="op">!</span><span class="kw">str_detect</span>(sotu_whole<span class="op">$</span>text, <span class="st">&quot;[C|c]itizen&quot;</span>)]</code></pre>
<ul>
<li>Get me the first 5 words for each speech</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">word</span>(sotu_whole<span class="op">$</span>text, <span class="dt">end =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unique</span>()</code></pre>
<ul>
<li>Now remove newline character (<code>\n</code>) and get rid of the leading white space:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">word</span>(sotu_whole<span class="op">$</span>text, <span class="dt">end =</span> <span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unique</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">str_replace_all</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">n&quot;</span>, <span class="st">&quot; &quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">str_trim</span>()</code></pre>
<p>(For spell checks take a look at <a href="https://CRAN.R-project.org/package=spelling" class="uri">https://CRAN.R-project.org/package=spelling</a> or <a href="https://CRAN.R-project.org/package=hunspell" class="uri">https://CRAN.R-project.org/package=hunspell</a>)</p>
</div>
<div id="tokenize-lowercase" class="section level2">
<h2><span class="header-section-number">1.3</span> Tokenize, lowercase</h2>
<p>A very common part of data cleaning involves tokenization. While our data is already “tidy” insofar as each row is a single observation, a single text with metdata, the tidytext approach goes a step further to make each word it’s own observation with metadata. We could write our own function to do this using a tokenizer, but <code>tidytext</code> provides a handy utility function just for this purpose.</p>
<pre class="sourceCode r"><code class="sourceCode r">tidy_sotu &lt;-<span class="st"> </span>sotu_whole <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(word, text)

tidy_sotu</code></pre>
<p>Before we move on, we should note that the <code>unnest_tokens</code> function didn’t just tokenize our texts at the word level. It also lowercased each word, and it could do quite a bit more. For instance, we could tokenize the text at the level of ngrams or sentences, if those are the best units of analysis for our work. We could also leave punctuation, which has been removed by default. Depending on what you need to do for analysis, you use do these operations during this step, or write custom functions and do it before you unnest tokens.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Word tokenization with punctuation</span>
tidy_sotu_w_punct &lt;-<span class="st"> </span>sotu_whole <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(word, text, <span class="dt">strip_punct =</span> <span class="ot">FALSE</span>)

tidy_sotu_w_punct

<span class="co"># Sentence tokenization</span>
tidy_sotu_sentences &lt;-<span class="st"> </span>sotu_whole <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(sentence, text, <span class="dt">token =</span> <span class="st">&quot;sentences&quot;</span>, <span class="dt">to_lower =</span> <span class="ot">FALSE</span>)

tidy_sotu_sentences

<span class="co"># N-gram tokenization</span>
tidy_sotu_trigram &lt;-<span class="st"> </span>sotu_whole <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">unnest_tokens</span>(trigram, text, <span class="dt">token =</span> <span class="st">&quot;ngrams&quot;</span>, <span class="dt">n =</span> <span class="dv">3</span>)

tidy_sotu_trigram</code></pre>
</div>
<div id="stopwords" class="section level2">
<h2><span class="header-section-number">1.4</span> Stopwords</h2>
<p>Another common type of cleaning in text analysis is to remove stopwords, or common words that theoretically provide less information about the content of a text. Depending on the type of analysis you’re doing, you might leave these words in or use a highly curated list of stopwords. For now, as we move toward looking at words in documents based on frequency, we will remove some standard stopwords using a tidytext approach.</p>
<p>First, let’s look at the stopwords that tidytext gives us to get a sense of what they are.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(stop_words)
<span class="kw">head</span>(stop_words, <span class="dt">n =</span> <span class="dv">60</span>)</code></pre>
<p>You can see that we now have one word per row with associated metadata. We can now remove stopwords using an <code>anti-join</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">tidy_sotu_words &lt;-<span class="st"> </span>tidy_sotu <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">anti_join</span>(stop_words)

tidy_sotu_words</code></pre>
<p>We went from 1965212 to 778161 rows, which means we had a lot of stopwords in our corpus. This is a huge removal, so for serious analysis, we might want to take a closer look at the stopwords and determine if we should use a different stopword list or otherwise create our own.</p>
</div>
<div id="word-stemming" class="section level2">
<h2><span class="header-section-number">1.5</span> Word Stemming</h2>
<p>Another thing you may want to do is to stem your words, that is, to reduce them to their word stem or root form, like reducing <em>fishing</em>, <em>fished</em>, and <em>fisher</em> to the stem <em>fish</em>.</p>
<p><code>tidytext</code> does not implement its own word stemmer. Instead it relies on separate packages like <code>hunspell</code> or <code>SnowballC</code>.</p>
<p>We will give an example here for the <code>SnowballC</code> package. (<code>hunspell</code> appears to run much slower, and it also returns a list instead of a vector, so in this context <code>SnowballC</code> seems to be more convenient.)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SnowballC)
tidy_sotu_words <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">word_stem =</span> <span class="kw">wordStem</span>(word)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre>
<p>For lemmatization, you may want to take a look a the <a href="https://CRAN.R-project.org/package=koRpus"><code>koRpus</code></a> package, another <a href="https://cran.r-project.org/web/packages/koRpus/vignettes/koRpus_vignette.html">comprehensive R package for text analysis</a>. It allows to use <a href="http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/">TreeTagger</a>, a widely used part-of-speech tagger. For full functionality of the R package a local installation of TreeTagger is recommended.</p>
<p>Now that we’ve read in our text and metadata, reshaped it a bit into the tidytext format, and cleaned it a bit while doing so, let’s move on to some basic analysis.</p>
<p>TODO?: Tag text with cleanNLP maybe?</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="textprep.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/cengel/R-text-analysis/edit/master/01-data-prep.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["R-text-analysis.pdf", "R-text-analysis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
